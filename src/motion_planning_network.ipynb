{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2334,
     "status": "ok",
     "timestamp": 1641398061619,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "z20D5QbbqZcf",
    "outputId": "d7097c44-925b-4504-e9cb-de7400bc3494"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "from rich.progress import Progress\n",
    "from utils import get_abs_path, steer_to, lazy_states_contraction, is_feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1641398061619,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "YyuGAmOQsX_d"
   },
   "outputs": [],
   "source": [
    "def cv2_imshow(img):\n",
    "    img = np.concatenate((img[:,:,2:3], img[:,:,1:2], img[:,:,0:1]), axis=2)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641398064796,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "B41Pwj44qK5q"
   },
   "outputs": [],
   "source": [
    "project_path = get_abs_path(1)\n",
    "encoder_images_dir = project_path + '/data/encoder_train/maps/'\n",
    "\n",
    "train_images_dir = project_path + '/data/train/maps/'\n",
    "train_paths_dir = project_path + '/data/train/planned_maps/paths.json'\n",
    "test_konwn_maps_dir = project_path + '/data/test/maps/'\n",
    "test_konwn_maps_paths_dir = project_path + '/data/test/planned_maps/paths.json'\n",
    "test_unkonwn_maps_dir = project_path + '/data/valid/maps/'\n",
    "test_unkonwn_maps_paths_dir = project_path + '/data/valid/planned_maps/paths.json'\n",
    "\n",
    "model_dir = project_path + '/models/'\n",
    "enet_filename = model_dir + 'enet.pt'\n",
    "pnet_filename = model_dir + 'pnet.pt'\n",
    "\n",
    "train_enet = False\n",
    "train_pnet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064796,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "KEtVWFQvpwy0"
   },
   "outputs": [],
   "source": [
    "train_paths = {}\n",
    "with open(train_paths_dir) as f:\n",
    "  train_paths = json.load(f)\n",
    "\n",
    "test_known_map_paths = {}\n",
    "with open(test_konwn_maps_paths_dir) as f:\n",
    "  test_known_map_paths = json.load(f)\n",
    "\n",
    "test_unknown_map_paths = {}\n",
    "with open(test_unkonwn_maps_paths_dir) as f:\n",
    "  test_unknown_map_paths = json.load(f)\n",
    "\n",
    "print(\"Detected:\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(\"Train paths:\", len(train_paths))\n",
    "print(\"Test paths on known maps:\", len(test_known_map_paths))\n",
    "print(\"Test paths on unknown maps:\", len(test_unknown_map_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create dataset for training encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "jZs2xxFKxDSu"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_dir, transform = None, target_transform = None):\n",
    "\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        files = []\n",
    "        files.extend(glob.glob(self.images_dir + '*.png'))\n",
    "        return len(files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_path = self.images_dir + 'map_' + str(idx) + '_0.png'\n",
    "        image = torch.Tensor(plt.imread(image_path))\n",
    "        image = image.permute(2,1,0)\n",
    "        # image = read_image(image_path)\n",
    "        image = image[2, :, :]\n",
    "\n",
    "        state = []\n",
    "        if self.transform:\n",
    "            state = torch.get_rng_state()\n",
    "            image_in = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            torch.set_rng_state(state)\n",
    "            image_out = self.target_transform(image)\n",
    "\n",
    "        return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "okHRDeQhxbig"
   },
   "outputs": [],
   "source": [
    "encoder_data = ImageDataset(encoder_images_dir)\n",
    "\n",
    "samples_count = 2000\n",
    "training_percentage = 0.9\n",
    "test_percentage = 0.1\n",
    "\n",
    "training_count = int(samples_count * training_percentage)\n",
    "test_count = int(samples_count * test_percentage)\n",
    "training_encoder_data, test_encoder_data = torch.utils.data.random_split(encoder_data, (training_count, test_count))\n",
    "\n",
    "train_encoder_dataloader = DataLoader(training_encoder_data, batch_size=16, shuffle=True, pin_memory=True)\n",
    "test_encoder_dataloader = DataLoader(test_encoder_data, batch_size=16, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "GioywhBN-pnJ"
   },
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    print(image.shape)\n",
    "    image = image * 255\n",
    "    image = image.permute(1, 2, 0).detach().numpy()\n",
    "    cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "QUFPEkCGuZuI",
    "outputId": "320cd75b-2b78-45e9-eb07-bff2870114b3"
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_encoder_dataloader))\n",
    "\n",
    "display_image(train_features[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064798,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "8v4ztNn-x2Mf",
    "outputId": "fe0c867e-11c1-46bd-a566-cab6fcfb650c"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {0} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create encoder model**\n",
    "\n",
    "Resnet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064798,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "M633Zvpjx9ny"
   },
   "outputs": [],
   "source": [
    "# def batch_norm_conv(ni, nf, stride=1):\n",
    "#     return nn.Sequential(\n",
    "#         nn.BatchNorm2d(ni),\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Conv2d(ni, nf, (3, 3), stride=stride, padding=1, bias=False)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064798,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "2SiASEm_yzs-"
   },
   "outputs": [],
   "source": [
    "# def conv1x1(ni, nf, stride=1):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Conv2d(ni, nf, (1, 1), stride=stride),\n",
    "#         nn.BatchNorm2d(nf)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064799,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "imgUlbSGy6bo"
   },
   "outputs": [],
   "source": [
    "# class ResBlock(nn.Module):\n",
    "\n",
    "#     def __init__(self, ni, nf, stride=1):\n",
    "#         super(ResBlock, self).__init__()\n",
    "#         self.shortcut = conv1x1(ni, nf, stride=stride)\n",
    "#         self.Bn1 = batch_norm_conv(ni, nf, stride=stride)\n",
    "#         self.Bn2 = batch_norm_conv(nf, nf)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         short = self.shortcut(x)\n",
    "#         x = self.Bn1(x)\n",
    "#         x = self.Bn2(x)\n",
    "#         return x.add(short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064799,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "v0UiVu1UzXiN"
   },
   "outputs": [],
   "source": [
    "# class ResEncoder(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(ResEncoder, self).__init__()\n",
    "\n",
    "#         self.short1 = conv1x1(1, 2)\n",
    "#         self.conv1 = nn.Conv2d(1, 2, (3, 3), padding=1)\n",
    "#         self.Bn1 = batch_norm_conv(2, 2)\n",
    "#         self.Res1 = ResBlock(2, 4)\n",
    "#         self.Res2 = ResBlock(4, 8, stride=2)\n",
    "#         self.Res3 = ResBlock(8, 16, stride=2)\n",
    "#         self.Res4 = ResBlock(16, 16, stride=2)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         r = self.short1(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.Bn1(x)\n",
    "#         x = x.add(r)\n",
    "#         short1 = torch.clone(x)\n",
    "\n",
    "#         x = self.Res1(x)\n",
    "#         short2 = torch.clone(x)\n",
    "#         x = self.Res2(x)\n",
    "#         short3 = torch.clone(x)\n",
    "#         x = self.Res3(x)\n",
    "#         short4 = torch.clone(x)\n",
    "#         x = self.Res4(x)\n",
    "\n",
    "#         return x, short1, short2, short3, short4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064799,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "KFHhTeZdzpfR"
   },
   "outputs": [],
   "source": [
    "# class ResDecoder(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(ResDecoder, self).__init__()\n",
    "\n",
    "#         self.Up1 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "#         self.Up2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "#         self.Up3 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "#         self.Up4 = nn.UpsamplingBilinear2d(scale_factor=1)\n",
    "\n",
    "#         self.Res5 = ResBlock(32, 8)\n",
    "#         self.Res6 = ResBlock(16, 4)\n",
    "#         self.Res7 = ResBlock(8, 2)\n",
    "#         self.Res8 = ResBlock(4, 2)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(2, 1, (1, 1))\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "#     def forward(self, x, short1, short2, short3, short4):\n",
    "\n",
    "#         x = self.Up1(x)\n",
    "#         x = torch.cat((short4, x), dim=1)\n",
    "#         x = self.Res5(x)\n",
    "\n",
    "#         x = self.Up2(x)\n",
    "#         x = torch.cat((short3, x), dim=1)\n",
    "#         x = self.Res6(x)\n",
    "\n",
    "#         x = self.Up3(x)\n",
    "#         x = torch.cat((short2, x), dim=1)\n",
    "#         x = self.Res7(x)\n",
    "\n",
    "#         x = self.Up4(x)\n",
    "#         x = torch.cat((short1, x), dim=1)\n",
    "#         x = self.Res8(x)\n",
    "\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.sigmoid(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064799,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "LdqrFsixzOGl",
    "outputId": "00b0d18f-b00f-4073-d70b-fe9d9c2ca7d5"
   },
   "outputs": [],
   "source": [
    "# class ResUNet(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(ResUNet, self).__init__()\n",
    "\n",
    "#         self.Encoder = ResEncoder()\n",
    "#         self.Decoder = ResDecoder()\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x, short1, short2, short3, short4 = self.Encoder(x)\n",
    "#         x = self.Decoder(x, short1, short2, short3, short4)\n",
    "#         return x\n",
    "\n",
    "# Enet = ResUNet().to(device)\n",
    "# # print(Enet.Encoder)\n",
    "# # print(Enet.Decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\t\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.dense1 = nn.Sequential(nn.Linear(14400, 512), nn.PReLU())\n",
    "\t\tself.dense2 = nn.Sequential(nn.Linear(512, 256), nn.PReLU())\n",
    "\t\tself.dense3 = nn.Sequential(nn.Linear(256, 128), nn.PReLU())\n",
    "\t\tself.dense4 = nn.Linear(128, 28)\n",
    "\t\t\t\n",
    "\tdef forward(self, x):\n",
    "\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = self.dense4(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\n",
    "\t\tself.dense1 = nn.Sequential(nn.Linear(28, 128), nn.PReLU())\n",
    "\t\tself.dense2 = nn.Sequential(nn.Linear(128, 256), nn.PReLU())\n",
    "\t\tself.dense3 = nn.Sequential(nn.Linear(256, 512), nn.PReLU())\n",
    "\t\tself.dense4 = nn.Sequential(nn.Linear(512, 14400))\n",
    "\t\tself.unflatten = nn.Unflatten(1, (120, 120))\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = self.dense4(x)\n",
    "\t\tx = self.unflatten(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResUNet, self).__init__()\n",
    "\n",
    "        self.Encoder = Encoder()\n",
    "        self.Decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x\n",
    "\n",
    "Enet = ResUNet().to(device)\n",
    "# print(Enet.Encoder)\n",
    "# print(Enet.Decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1641398064799,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "5ndEB0UP2zAX"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Enet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064800,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "3jCsfnuo2_VY"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'Loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1641398065281,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "NGCOrIAd5EiH"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    # correct /= size\n",
    "    print(f'Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9190,
     "status": "ok",
     "timestamp": 1641398074469,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "bYtDJkXN36hr",
    "outputId": "ccda881d-d536-446c-c2c2-10e059ba8673"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(enet_filename) or train_enet == True:\n",
    "    epochs = 400\n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t+1}\\n-------------------------------')\n",
    "        train(train_encoder_dataloader, Enet, loss_fn, optimizer)\n",
    "        test(test_encoder_dataloader, Enet, loss_fn)\n",
    "    print('Done!')\n",
    "    torch.save(Enet.state_dict(), enet_filename)\n",
    "else:\n",
    "    Enet.load_state_dict(torch.load(enet_filename))\n",
    "    Enet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1641398303376,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "QCQgyA_15PvK",
    "outputId": "cad80819-974e-40b4-c66a-def1b9ffc767"
   },
   "outputs": [],
   "source": [
    "# Display Results\n",
    "test_features, test_labels = next(iter(test_encoder_dataloader))\n",
    "display_image(test_features[0].unsqueeze(0))\n",
    "display_image(test_labels[0].unsqueeze(0))\n",
    "\n",
    "result = Enet(test_labels.to(device))\n",
    "result = result.cpu()\n",
    "display_image(result[0].unsqueeze(0))\n",
    "print(Enet.Encoder(test_labels.to(device))[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create path planning dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataset(Dataset):\n",
    "\n",
    "    def __init__(self, encoder, images_dir, paths):\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.images_dir = images_dir\n",
    "        self.paths = paths\n",
    "\n",
    "        self.keys = []\n",
    "        for key in paths.keys():\n",
    "            self.keys.append(key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_path = self.images_dir + self.keys[idx]\n",
    "        image = Tensor(plt.imread(image_path)).to(device)\n",
    "        image = image.permute(2,1,0)\n",
    "        image = image[2:3, :, :]\n",
    "\n",
    "        encoded_img = self.encoder(image.unsqueeze(0))[0].detach().cpu()\n",
    "\n",
    "        # to replace bad path TODO fix\n",
    "        path_len = 0\n",
    "        i = idx\n",
    "        while path_len < 2:\n",
    "            map_name = self.keys[i]\n",
    "            planned_path = Tensor(self.paths[map_name])\n",
    "            path_len = len(planned_path)\n",
    "            i = np.random.randint(0, self.__len__())\n",
    "        if path_len > 2:\n",
    "            point_idx = np.random.randint(0, path_len - 2)\n",
    "        else:\n",
    "            point_idx = 0\n",
    "\n",
    "        image_width = image.shape[1]\n",
    "        x_start = planned_path[point_idx]\n",
    "        x_goal = planned_path[-1]\n",
    "        x_pred = planned_path[point_idx + 1]\n",
    "        x_pred = x_pred\n",
    "\n",
    "        # value normalization\n",
    "        # x_start /= image_width\n",
    "        # x_goal /= image_width\n",
    "        # x_pred /= image_width\n",
    "\n",
    "        input_data = torch.cat([torch.flatten(encoded_img), x_start, x_goal])\n",
    "        input_data.requires_grad = True\n",
    "        \n",
    "        return input_data, x_pred\n",
    "\n",
    "\n",
    "train_dataset = PathDataset(Enet.Encoder, train_images_dir, train_paths)\n",
    "test_dataset_known_maps = PathDataset(Enet.Encoder, test_konwn_maps_dir, test_known_map_paths)\n",
    "test_dataset_unknown_maps = PathDataset(Enet.Encoder, test_unkonwn_maps_dir, test_unknown_map_paths)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True, pin_memory=True)\n",
    "test_dataloader_known_maps = DataLoader(test_dataset_known_maps, batch_size=50, shuffle=True, pin_memory=True)\n",
    "test_dataloader_unknown_maps = DataLoader(test_dataset_unknown_maps, batch_size=50, shuffle=True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlanningNetwork(nn.Module):\n",
    "#     def __init__(self, p=0.1):\n",
    "#         super(PlanningNetwork, self).__init__()\n",
    "\n",
    "#         enc_img_size = 3600\n",
    "#         self.dense1 = nn.Sequential(nn.Linear(enc_img_size, 512), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense2 = nn.Sequential(nn.Linear(512, 256), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense3 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense4 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense5 = nn.Sequential(nn.Linear(64, 32), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense6 = nn.Sequential(nn.Linear(32, 16), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense7 = nn.Sequential(nn.Linear(16, 4), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense8 = nn.Sequential(nn.Linear(4, 2), nn.PReLU(), nn.Dropout(p))\n",
    "\n",
    "#         self.dense9 = nn.Sequential(nn.Linear(4, 4), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense10 = nn.Sequential(nn.Linear(4, 2), nn.PReLU())\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         c = x[:, -4:]\n",
    "#         x = x[:, :-4]\n",
    "\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dense3(x)\n",
    "#         x = self.dense4(x)\n",
    "#         x = self.dense5(x)\n",
    "#         x = self.dense6(x)\n",
    "#         x = self.dense7(x)\n",
    "#         x = self.dense8(x)\n",
    "\n",
    "#         c = self.dense9(c)\n",
    "#         c = self.dense10(c)\n",
    "\n",
    "#         x = torch.add(x, c)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# Pnet = PlanningNetwork().to(device)\n",
    "# print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlanningNetwork(nn.Module):\n",
    "#     def __init__(self, p=0.05):\n",
    "#         super(PlanningNetwork, self).__init__()\n",
    "\n",
    "#         enc_img_size = 3600\n",
    "\n",
    "#         self.norm = nn.Sequential(nn.Linear(enc_img_size, 512), nn.PReLU(), nn.Dropout(p))\n",
    "\n",
    "#         self.up_dense1 = nn.Sequential(nn.Linear(4, 8), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense2 = nn.Sequential(nn.Linear(8, 16), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense3 = nn.Sequential(nn.Linear(16, 32), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense4 = nn.Sequential(nn.Linear(32, 64), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense5 = nn.Sequential(nn.Linear(64, 128), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense6 = nn.Sequential(nn.Linear(128, 256), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense7 = nn.Sequential(nn.Linear(256, 512), nn.PReLU(), nn.Dropout(p))\n",
    "\n",
    "#         self.dense1 = nn.Sequential(nn.Linear(1024, 512), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense2 = nn.Sequential(nn.Linear(512, 256), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense3 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense4 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense5 = nn.Sequential(nn.Linear(64, 32), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense6 = nn.Sequential(nn.Linear(32, 16), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense7 = nn.Sequential(nn.Linear(16, 8), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense8 = nn.Sequential(nn.Linear(8, 4), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense9 = nn.Sequential(nn.Linear(4, 2), nn.PReLU())\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         c = x[:, -4:]\n",
    "#         x = x[:, :-4]\n",
    "\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         c = self.up_dense1(c)\n",
    "#         c = self.up_dense2(c)\n",
    "#         c = self.up_dense3(c)\n",
    "#         c = self.up_dense4(c)\n",
    "#         c = self.up_dense5(c)\n",
    "#         c = self.up_dense6(c)\n",
    "#         c = self.up_dense7(c)\n",
    "\n",
    "#         x = torch.cat([x ,c], dim=1)\n",
    "\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dense3(x)\n",
    "#         x = self.dense4(x)\n",
    "#         x = self.dense5(x)\n",
    "#         x = self.dense6(x)\n",
    "#         x = self.dense7(x)\n",
    "#         x = self.dense8(x)\n",
    "#         x = self.dense9(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# Pnet = PlanningNetwork().to(device)\n",
    "# print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanningNetwork(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(PlanningNetwork, self).__init__()\n",
    "\n",
    "        enc_img_size = 32\n",
    "        self.dense1 = nn.Sequential(nn.Linear(enc_img_size, 1280), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense2 = nn.Sequential(nn.Linear(1280, 1024), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense3 = nn.Sequential(nn.Linear(1024, 896), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense4 = nn.Sequential(nn.Linear(896, 768), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense5 = nn.Sequential(nn.Linear(768, 512), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense6 = nn.Sequential(nn.Linear(512, 384), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense7 = nn.Sequential(nn.Linear(384, 256), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense8 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense9 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense10 = nn.Sequential(nn.Linear(64, 32), nn.PReLU())\n",
    "        self.dense11 = nn.Sequential(nn.Linear(32, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        x = self.dense7(x)\n",
    "        x = self.dense8(x)\n",
    "        x = self.dense9(x)\n",
    "        x = self.dense10(x)\n",
    "        x = self.dense11(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "Pnet = PlanningNetwork().to(device)\n",
    "print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pnet_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "\n",
    "        loss = Tensor([0]).to(device)\n",
    "        for i in range(len(target)):\n",
    "            loss += torch.square(output[i, 0] - target[i, 0])\n",
    "            loss += torch.square(output[i, 1] - target[i, 1])\n",
    "        \n",
    "        loss /= (target.shape[0] * 2)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = Pnet_loss()\n",
    "optimizer = torch.optim.Adagrad(Pnet.parameters(), lr=1e-4)\n",
    "\n",
    "if not os.path.exists(pnet_filename) or train_pnet == True:\n",
    "    epochs = 100\n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t+1}\\n-------------------------------')\n",
    "        train(train_dataloader, Pnet, loss_fn.forward, optimizer)\n",
    "        test(test_dataloader_known_maps, Pnet, loss_fn.forward)\n",
    "        test(test_dataloader_unknown_maps, Pnet, loss_fn.forward)\n",
    "    print('Done!')\n",
    "    torch.save(Pnet.state_dict(), pnet_filename)\n",
    "else:\n",
    "    Pnet.load_state_dict(torch.load(pnet_filename))\n",
    "    Pnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "i = 0\n",
    "image_path = test_konwn_maps_dir + 'map_' + str(i) + '_0.png'\n",
    "image = Tensor(plt.imread(image_path)).to(device)\n",
    "image = image.permute(2,1,0)\n",
    "image = image[2:3, :, :]\n",
    "\n",
    "encoded_img = Enet.Encoder(image.unsqueeze(0))[0].detach().cpu()\n",
    "\n",
    "planned_path = Tensor(test_known_map_paths['map_' + str(i) + '_0.png'])\n",
    "path_len = len(planned_path)\n",
    "\n",
    "if path_len > 2:\n",
    "    point_idx = np.random.randint(0, path_len - 2)\n",
    "else:\n",
    "    point_idx = 0\n",
    "\n",
    "x_start = planned_path[point_idx] / image.shape[-1]\n",
    "x_goal = planned_path[-1] / image.shape[-1]\n",
    "x_pred = planned_path[point_idx + 1] / image.shape[-1]\n",
    "input_data = torch.cat([torch.flatten(encoded_img), x_start, x_goal])\n",
    "\n",
    "print(input_data.to(device).unsqueeze(0))\n",
    "\n",
    "result = Pnet(input_data.to(device).unsqueeze(0))\n",
    "\n",
    "i = 0\n",
    "for point in [x_start, x_goal, result[0].detach().cpu()]:\n",
    "    print(point)\n",
    "    x, y = point.numpy()\n",
    "    x*=120\n",
    "    y*=120\n",
    "\n",
    "    p = 0.6\n",
    "\n",
    "    if i > 1:\n",
    "        p = 0.25\n",
    "\n",
    "    image[:, int(x) - 1, int(y) - 1] = p\n",
    "    image[:, int(x) - 1, int(y)] = p\n",
    "    image[:, int(x) - 1, int(y) + 1] = p\n",
    "    image[:, int(x), int(y) - 1] = p\n",
    "    image[:, int(x), int(y)] = p\n",
    "    image[:, int(x), int(y) + 1] = p\n",
    "    image[:, int(x) + 1, int(y) - 1] = p\n",
    "    image[:, int(x) + 1, int(y)] = p\n",
    "    image[:, int(x) + 1, int(y) + 1] = p\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0).detach().cpu().numpy(), cmap='gray')\n",
    "\n",
    "print(x_start*120, x_goal*120, x_pred*120)\n",
    "print(result.shape, x_pred.shape)\n",
    "print(result.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replaning(a, b):\n",
    "    pass\n",
    "\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1\n",
    "def MPNet(x_init, x_goal, x_obs):\n",
    "    Z = Enet.Encoder(x_obs)\n",
    "    Tau = NeuralPlanner(x_init, x_goal, Z)\n",
    "    if Tau:\n",
    "        Tau = lazy_states_contraction(Tau)\n",
    "\n",
    "        if is_feasible(Tau):\n",
    "            return Tau\n",
    "        else:\n",
    "            Tau_new = Replaning(Tau, Z)\n",
    "            Tau_new = lazy_states_contraction(Tau_new)\n",
    "            if is_feasible(Tau_new):\n",
    "                return Tau_new\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 2\n",
    "def NeuralPlanner(x_start, x_goal, Z):\n",
    "    Tau_a = [x_start]\n",
    "    Tau_b = [x_goal]\n",
    "    Tau = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        x_new = Pnet(Z, Tau_a[-1], Tau_b[-1])\n",
    "        Tau_a.append(x_new)\n",
    "        connectable = steer_to(Tau_a[-1], Tau_b[-1])\n",
    "\n",
    "        if connectable:\n",
    "            Tau = np.concatenate((Tau_a, Tau_b))\n",
    "            return Tau\n",
    "\n",
    "        Tau_a, Tau_b = Tau_b, Tau_a\n",
    "\n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPwQqSrx/eWM5U7H1MeaJ9I",
   "collapsed_sections": [],
   "name": "motion_planning_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
