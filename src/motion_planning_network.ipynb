{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2334,
     "status": "ok",
     "timestamp": 1641398061619,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "z20D5QbbqZcf",
    "outputId": "d7097c44-925b-4504-e9cb-de7400bc3494"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from rich.progress import Progress\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "from utils import get_abs_path, steer_to, lazy_states_contraction, is_feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1641398061619,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "YyuGAmOQsX_d"
   },
   "outputs": [],
   "source": [
    "def cv2_imshow(img):\n",
    "    img = np.concatenate((img[:,:,2:3], img[:,:,1:2], img[:,:,0:1]), axis=2)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    print(image.shape)\n",
    "    image = image * 255\n",
    "    image = image.permute(1, 2, 0).detach().numpy()\n",
    "    cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641398064796,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "B41Pwj44qK5q"
   },
   "outputs": [],
   "source": [
    "project_path = get_abs_path(1)\n",
    "\n",
    "model_dir = project_path + '/models/'\n",
    "enet_filename = model_dir + 'enet.pt'\n",
    "pnet_filename = model_dir + 'pnet.pt'\n",
    "\n",
    "data_path = project_path + '/data/'\n",
    "encoder_images_dir = data_path + 'encoder_images/'\n",
    "train_images_dir = data_path + 'train/maps/'\n",
    "train_paths_dir = data_path + 'train/planned_maps/'\n",
    "test_konwn_maps_dir = data_path + 'test/maps/'\n",
    "test_konwn_maps_paths_dir = data_path + 'test/planned_maps/'\n",
    "test_unkonwn_maps_dir = data_path + 'valid/maps/'\n",
    "test_unkonwn_maps_paths_dir = data_path + 'valid/planned_maps/'\n",
    "\n",
    "train_enet = False\n",
    "train_pnet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create dataset for training encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "jZs2xxFKxDSu"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_paths):\n",
    "        self.images_paths = images_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images_paths[idx]\n",
    "        image = torch.Tensor(plt.imread(image_path))\n",
    "        image = image.permute(2,1,0)\n",
    "        image = image[2, :, :]\n",
    "        return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "okHRDeQhxbig"
   },
   "outputs": [],
   "source": [
    "encoder_images_paths = glob.glob(encoder_images_dir + '*.png')\n",
    "train_encoder_paths, test_encoder_paths = train_test_split(encoder_images_paths, test_size=0.2)\n",
    "valid_encoder_paths, test_encoder_paths = train_test_split(test_encoder_paths, test_size=0.5)\n",
    "\n",
    "train_encoder_data = ImageDataset(train_encoder_paths)\n",
    "valid_encoder_data = ImageDataset(valid_encoder_paths)\n",
    "test_encoder_data = ImageDataset(test_encoder_paths)\n",
    "\n",
    "batch_size = 16\n",
    "train_encoder_dataloader = DataLoader(train_encoder_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_encoder_dataloader = DataLoader(valid_encoder_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_encoder_dataloader = DataLoader(test_encoder_data, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "QUFPEkCGuZuI",
    "outputId": "320cd75b-2b78-45e9-eb07-bff2870114b3"
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_encoder_dataloader))\n",
    "display_image(train_features[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064798,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "8v4ztNn-x2Mf",
    "outputId": "fe0c867e-11c1-46bd-a566-cab6fcfb650c"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {0} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create encoder model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, input_size):\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.dense1 = nn.Sequential(nn.Linear(input_size, 1512), nn.PReLU())\n",
    "\t\tself.dense2 = nn.Sequential(nn.Linear(1512, 556), nn.PReLU())\n",
    "\t\tself.dense3 = nn.Sequential(nn.Linear(556, 128), nn.PReLU())\n",
    "\t\tself.dense4 = nn.Linear(128, 32)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = self.dense4(x)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, output_size):\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\t\tself.dense1 = nn.Sequential(nn.Linear(32, 128), nn.PReLU())\n",
    "\t\tself.dense2 = nn.Sequential(nn.Linear(128, 556), nn.PReLU())\n",
    "\t\tself.dense3 = nn.Sequential(nn.Linear(556, 1512), nn.PReLU())\n",
    "\t\tself.dense4 = nn.Sequential(nn.Linear(1512, output_size))\n",
    "\t\tself.unflatten = nn.Unflatten(1, (120, 120))\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = self.dense4(x)\n",
    "\t\tx = self.unflatten(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ResUNet, self).__init__()\n",
    "        self.Encoder = Encoder(input_size)\n",
    "        self.Decoder = Decoder(input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x\n",
    "\n",
    "Enet = ResUNet(14400).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064800,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "3jCsfnuo2_VY"
   },
   "outputs": [],
   "source": [
    "def loss_fn(model, output, target):\n",
    "\n",
    "    return nn.MSELoss(output, target)\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataloader, valid_dataloader):\n",
    "\n",
    "    for i in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(model, pred, y)\n",
    "            total_train_loss += loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in valid_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(model, pred, y)\n",
    "                total_valid_loss += loss\n",
    "\n",
    "        print('Epoch %d/%d' % (i+1, epochs))\n",
    "        print('Train loss %f Valid loss %f' % (total_train_loss / len(train_dataloader), total_valid_loss / len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1641398065281,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "NGCOrIAd5EiH"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(model, pred, y).item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    print(f'Test loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9190,
     "status": "ok",
     "timestamp": 1641398074469,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "bYtDJkXN36hr",
    "outputId": "ccda881d-d536-446c-c2c2-10e059ba8673"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(Enet.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 30\n",
    "train(Enet, optimizer, train_encoder_dataloader, valid_encoder_dataloader)\n",
    "test(Enet, test_encoder_dataloader)\n",
    "torch.save(Enet.state_dict(), enet_filename)\n",
    "\n",
    "# if not os.path.exists(enet_filename) or train_enet == True:\n",
    "#     epochs = 10\n",
    "#     train(Enet, loss_fn, optimizer, train_encoder_dataloader)\n",
    "#     test(Enet, loss_fn, test_encoder_dataloader)\n",
    "#     torch.save(Enet.state_dict(), enet_filename)\n",
    "# else:\n",
    "#     Enet.load_state_dict(torch.load(enet_filename))\n",
    "#     Enet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1641398303376,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "QCQgyA_15PvK",
    "outputId": "cad80819-974e-40b4-c66a-def1b9ffc767"
   },
   "outputs": [],
   "source": [
    "# Display Results\n",
    "test_features, test_labels = next(iter(test_encoder_dataloader))\n",
    "display_image(test_features[0].unsqueeze(0))\n",
    "display_image(test_labels[0].unsqueeze(0))\n",
    "\n",
    "result = Enet(test_labels.to(device))\n",
    "result = result.cpu()\n",
    "display_image(result[0].unsqueeze(0))\n",
    "print(Enet.Encoder(test_labels.to(device))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = Enet.Encoder(test_labels.to(device))[0]\n",
    "print(encoded)\n",
    "display_image(Enet.Decoder(encoded.unsqueeze(0)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_val = (torch.rand(32) * 20) - 10\n",
    "rand_val = rand_val.to(device)\n",
    "display_image(Enet.Decoder(rand_val.unsqueeze(0)).cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create path planning dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataset(Dataset):\n",
    "\n",
    "    def __init__(self, encoder, images_dir, paths):\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.images_dir = images_dir\n",
    "        self.paths = paths\n",
    "\n",
    "        self.keys = []\n",
    "        for key in paths.keys():\n",
    "            self.keys.append(key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_path = self.images_dir + self.keys[idx]\n",
    "        image = Tensor(plt.imread(image_path)).to(device)\n",
    "        image = image.permute(2,1,0)\n",
    "        image = image[2:3, :, :]\n",
    "\n",
    "        encoded_img = self.encoder(image.unsqueeze(0))[0].detach().cpu()\n",
    "\n",
    "        # to replace bad path TODO fix\n",
    "        path_len = 0\n",
    "        i = idx\n",
    "        while path_len < 2:\n",
    "            map_name = self.keys[i]\n",
    "            planned_path = Tensor(self.paths[map_name])\n",
    "            path_len = len(planned_path)\n",
    "            i = np.random.randint(0, self.__len__())\n",
    "        if path_len > 2:\n",
    "            point_idx = np.random.randint(0, path_len - 2)\n",
    "        else:\n",
    "            point_idx = 0\n",
    "\n",
    "        image_width = image.shape[1]\n",
    "        x_start = planned_path[point_idx]\n",
    "        x_goal = planned_path[-1]\n",
    "        x_pred = planned_path[point_idx + 1]\n",
    "        x_pred = x_pred\n",
    "\n",
    "        # value normalization\n",
    "        # x_start /= image_width\n",
    "        # x_goal /= image_width\n",
    "        # x_pred /= image_width\n",
    "\n",
    "        input_data = torch.cat([torch.flatten(encoded_img), x_start, x_goal])\n",
    "        input_data.requires_grad = True\n",
    "        \n",
    "        return input_data, x_pred\n",
    "\n",
    "\n",
    "train_dataset = PathDataset(Enet.Encoder, train_images_dir, train_paths)\n",
    "test_dataset_known_maps = PathDataset(Enet.Encoder, test_konwn_maps_dir, test_known_map_paths)\n",
    "test_dataset_unknown_maps = PathDataset(Enet.Encoder, test_unkonwn_maps_dir, test_unknown_map_paths)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True, pin_memory=True)\n",
    "test_dataloader_known_maps = DataLoader(test_dataset_known_maps, batch_size=50, shuffle=True, pin_memory=True)\n",
    "test_dataloader_unknown_maps = DataLoader(test_dataset_unknown_maps, batch_size=50, shuffle=True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlanningNetwork(nn.Module):\n",
    "#     def __init__(self, p=0.1):\n",
    "#         super(PlanningNetwork, self).__init__()\n",
    "\n",
    "#         enc_img_size = 3600\n",
    "#         self.dense1 = nn.Sequential(nn.Linear(enc_img_size, 512), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense2 = nn.Sequential(nn.Linear(512, 256), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense3 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense4 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense5 = nn.Sequential(nn.Linear(64, 32), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense6 = nn.Sequential(nn.Linear(32, 16), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense7 = nn.Sequential(nn.Linear(16, 4), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense8 = nn.Sequential(nn.Linear(4, 2), nn.PReLU(), nn.Dropout(p))\n",
    "\n",
    "#         self.dense9 = nn.Sequential(nn.Linear(4, 4), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense10 = nn.Sequential(nn.Linear(4, 2), nn.PReLU())\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         c = x[:, -4:]\n",
    "#         x = x[:, :-4]\n",
    "\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dense3(x)\n",
    "#         x = self.dense4(x)\n",
    "#         x = self.dense5(x)\n",
    "#         x = self.dense6(x)\n",
    "#         x = self.dense7(x)\n",
    "#         x = self.dense8(x)\n",
    "\n",
    "#         c = self.dense9(c)\n",
    "#         c = self.dense10(c)\n",
    "\n",
    "#         x = torch.add(x, c)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# Pnet = PlanningNetwork().to(device)\n",
    "# print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlanningNetwork(nn.Module):\n",
    "#     def __init__(self, p=0.05):\n",
    "#         super(PlanningNetwork, self).__init__()\n",
    "\n",
    "#         enc_img_size = 3600\n",
    "\n",
    "#         self.norm = nn.Sequential(nn.Linear(enc_img_size, 512), nn.PReLU(), nn.Dropout(p))\n",
    "\n",
    "#         self.up_dense1 = nn.Sequential(nn.Linear(4, 8), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense2 = nn.Sequential(nn.Linear(8, 16), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense3 = nn.Sequential(nn.Linear(16, 32), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense4 = nn.Sequential(nn.Linear(32, 64), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense5 = nn.Sequential(nn.Linear(64, 128), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense6 = nn.Sequential(nn.Linear(128, 256), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.up_dense7 = nn.Sequential(nn.Linear(256, 512), nn.PReLU(), nn.Dropout(p))\n",
    "\n",
    "#         self.dense1 = nn.Sequential(nn.Linear(1024, 512), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense2 = nn.Sequential(nn.Linear(512, 256), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense3 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense4 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense5 = nn.Sequential(nn.Linear(64, 32), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense6 = nn.Sequential(nn.Linear(32, 16), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense7 = nn.Sequential(nn.Linear(16, 8), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense8 = nn.Sequential(nn.Linear(8, 4), nn.PReLU(), nn.Dropout(p))\n",
    "#         self.dense9 = nn.Sequential(nn.Linear(4, 2), nn.PReLU())\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         c = x[:, -4:]\n",
    "#         x = x[:, :-4]\n",
    "\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         c = self.up_dense1(c)\n",
    "#         c = self.up_dense2(c)\n",
    "#         c = self.up_dense3(c)\n",
    "#         c = self.up_dense4(c)\n",
    "#         c = self.up_dense5(c)\n",
    "#         c = self.up_dense6(c)\n",
    "#         c = self.up_dense7(c)\n",
    "\n",
    "#         x = torch.cat([x ,c], dim=1)\n",
    "\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dense3(x)\n",
    "#         x = self.dense4(x)\n",
    "#         x = self.dense5(x)\n",
    "#         x = self.dense6(x)\n",
    "#         x = self.dense7(x)\n",
    "#         x = self.dense8(x)\n",
    "#         x = self.dense9(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# Pnet = PlanningNetwork().to(device)\n",
    "# print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanningNetwork(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(PlanningNetwork, self).__init__()\n",
    "\n",
    "        enc_img_size = 32\n",
    "        self.dense1 = nn.Sequential(nn.Linear(enc_img_size, 1280), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense2 = nn.Sequential(nn.Linear(1280, 1024), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense3 = nn.Sequential(nn.Linear(1024, 896), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense4 = nn.Sequential(nn.Linear(896, 768), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense5 = nn.Sequential(nn.Linear(768, 512), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense6 = nn.Sequential(nn.Linear(512, 384), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense7 = nn.Sequential(nn.Linear(384, 256), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense8 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense9 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense10 = nn.Sequential(nn.Linear(64, 32), nn.PReLU())\n",
    "        self.dense11 = nn.Sequential(nn.Linear(32, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        x = self.dense7(x)\n",
    "        x = self.dense8(x)\n",
    "        x = self.dense9(x)\n",
    "        x = self.dense10(x)\n",
    "        x = self.dense11(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "Pnet = PlanningNetwork().to(device)\n",
    "print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pnet_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "\n",
    "        loss = Tensor([0]).to(device)\n",
    "        for i in range(len(target)):\n",
    "            loss += torch.square(output[i, 0] - target[i, 0])\n",
    "            loss += torch.square(output[i, 1] - target[i, 1])\n",
    "        \n",
    "        loss /= (target.shape[0] * 2)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = Pnet_loss()\n",
    "optimizer = torch.optim.Adagrad(Pnet.parameters(), lr=1e-4)\n",
    "\n",
    "if not os.path.exists(pnet_filename) or train_pnet == True:\n",
    "    epochs = 100\n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t+1}\\n-------------------------------')\n",
    "        train(train_dataloader, Pnet, loss_fn.forward, optimizer)\n",
    "        test(test_dataloader_known_maps, Pnet, loss_fn.forward)\n",
    "        test(test_dataloader_unknown_maps, Pnet, loss_fn.forward)\n",
    "    print('Done!')\n",
    "    torch.save(Pnet.state_dict(), pnet_filename)\n",
    "else:\n",
    "    Pnet.load_state_dict(torch.load(pnet_filename))\n",
    "    Pnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "i = 0\n",
    "image_path = test_konwn_maps_dir + 'map_' + str(i) + '_0.png'\n",
    "image = Tensor(plt.imread(image_path)).to(device)\n",
    "image = image.permute(2,1,0)\n",
    "image = image[2:3, :, :]\n",
    "\n",
    "encoded_img = Enet.Encoder(image.unsqueeze(0))[0].detach().cpu()\n",
    "\n",
    "planned_path = Tensor(test_known_map_paths['map_' + str(i) + '_0.png'])\n",
    "path_len = len(planned_path)\n",
    "\n",
    "if path_len > 2:\n",
    "    point_idx = np.random.randint(0, path_len - 2)\n",
    "else:\n",
    "    point_idx = 0\n",
    "\n",
    "x_start = planned_path[point_idx] / image.shape[-1]\n",
    "x_goal = planned_path[-1] / image.shape[-1]\n",
    "x_pred = planned_path[point_idx + 1] / image.shape[-1]\n",
    "input_data = torch.cat([torch.flatten(encoded_img), x_start, x_goal])\n",
    "\n",
    "print(input_data.to(device).unsqueeze(0))\n",
    "\n",
    "result = Pnet(input_data.to(device).unsqueeze(0))\n",
    "\n",
    "i = 0\n",
    "for point in [x_start, x_goal, result[0].detach().cpu()]:\n",
    "    print(point)\n",
    "    x, y = point.numpy()\n",
    "    x*=120\n",
    "    y*=120\n",
    "\n",
    "    p = 0.6\n",
    "\n",
    "    if i > 1:\n",
    "        p = 0.25\n",
    "\n",
    "    image[:, int(x) - 1, int(y) - 1] = p\n",
    "    image[:, int(x) - 1, int(y)] = p\n",
    "    image[:, int(x) - 1, int(y) + 1] = p\n",
    "    image[:, int(x), int(y) - 1] = p\n",
    "    image[:, int(x), int(y)] = p\n",
    "    image[:, int(x), int(y) + 1] = p\n",
    "    image[:, int(x) + 1, int(y) - 1] = p\n",
    "    image[:, int(x) + 1, int(y)] = p\n",
    "    image[:, int(x) + 1, int(y) + 1] = p\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0).detach().cpu().numpy(), cmap='gray')\n",
    "\n",
    "print(x_start*120, x_goal*120, x_pred*120)\n",
    "print(result.shape, x_pred.shape)\n",
    "print(result.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replaning(a, b):\n",
    "    pass\n",
    "\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1\n",
    "def MPNet(x_init, x_goal, x_obs):\n",
    "    Z = Enet.Encoder(x_obs)\n",
    "    Tau = NeuralPlanner(x_init, x_goal, Z)\n",
    "    if Tau:\n",
    "        Tau = lazy_states_contraction(Tau)\n",
    "\n",
    "        if is_feasible(Tau):\n",
    "            return Tau\n",
    "        else:\n",
    "            Tau_new = Replaning(Tau, Z)\n",
    "            Tau_new = lazy_states_contraction(Tau_new)\n",
    "            if is_feasible(Tau_new):\n",
    "                return Tau_new\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 2\n",
    "def NeuralPlanner(x_start, x_goal, Z):\n",
    "    Tau_a = [x_start]\n",
    "    Tau_b = [x_goal]\n",
    "    Tau = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        x_new = Pnet(Z, Tau_a[-1], Tau_b[-1])\n",
    "        Tau_a.append(x_new)\n",
    "        connectable = steer_to(Tau_a[-1], Tau_b[-1])\n",
    "\n",
    "        if connectable:\n",
    "            Tau = np.concatenate((Tau_a, Tau_b))\n",
    "            return Tau\n",
    "\n",
    "        Tau_a, Tau_b = Tau_b, Tau_a\n",
    "\n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPwQqSrx/eWM5U7H1MeaJ9I",
   "collapsed_sections": [],
   "name": "motion_planning_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
