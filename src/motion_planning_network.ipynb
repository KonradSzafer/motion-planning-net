{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2334,
     "status": "ok",
     "timestamp": 1641398061619,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "z20D5QbbqZcf",
    "outputId": "d7097c44-925b-4504-e9cb-de7400bc3494"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import get_abs_path, steer_to, lazy_states_contraction, is_feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1641398061619,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "YyuGAmOQsX_d"
   },
   "outputs": [],
   "source": [
    "def cv2_imshow(img, title=None):\n",
    "    img = np.concatenate((img[:,:,2:3], img[:,:,1:2], img[:,:,0:1]), axis=2)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_image(image, title=None):\n",
    "    image = image * 255\n",
    "    image = image.permute(1, 2, 0).detach().numpy()\n",
    "    cv2_imshow(image, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641398064796,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "B41Pwj44qK5q"
   },
   "outputs": [],
   "source": [
    "project_path = get_abs_path(1)\n",
    "\n",
    "model_dir = project_path + '/models/'\n",
    "enet_filename = model_dir + 'enet.pt'\n",
    "pnet_filename = model_dir + 'pnet.pt'\n",
    "\n",
    "data_path = project_path + '/data/'\n",
    "encoder_images_dir = data_path + 'encoder_images/'\n",
    "train_images_dir = data_path + 'train/maps/'\n",
    "train_paths_dir = data_path + 'train/planned_maps/'\n",
    "\n",
    "valid_known_images_dir = data_path + 'valid/known_maps/'\n",
    "valid_known_paths_dir = data_path + 'valid/planned_known_maps/'\n",
    "valid_unknown_images_dir = data_path + 'valid/unknown_maps/'\n",
    "valid_unknown_paths_dir = data_path + 'valid/planned_unknown_maps/'\n",
    "\n",
    "test_known_images_dir = data_path + 'test/known_maps/'\n",
    "test_known_paths_dir = data_path + 'test/planned_known_maps/'\n",
    "test_unknown_images_dir = data_path + 'test/unknown_maps/'\n",
    "test_unknown_paths_dir = data_path + 'test/planned_unknown_maps/'\n",
    "\n",
    "train_enet = True\n",
    "train_pnet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create dataset for training encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "jZs2xxFKxDSu"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_paths):\n",
    "        self.images_paths = images_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images_paths[idx]\n",
    "        image = torch.Tensor(plt.imread(image_path))\n",
    "        image = image.permute(2,1,0)\n",
    "        image = image[2, :, :]\n",
    "        return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "okHRDeQhxbig"
   },
   "outputs": [],
   "source": [
    "encoder_images_paths = glob.glob(encoder_images_dir + '*.png')\n",
    "train_encoder_paths, test_encoder_paths = train_test_split(encoder_images_paths, test_size=0.2)\n",
    "valid_encoder_paths, test_encoder_paths = train_test_split(test_encoder_paths, test_size=0.5)\n",
    "\n",
    "train_encoder_data = ImageDataset(train_encoder_paths)\n",
    "valid_encoder_data = ImageDataset(valid_encoder_paths)\n",
    "test_encoder_data = ImageDataset(test_encoder_paths)\n",
    "\n",
    "batch_size = 5 #16\n",
    "train_encoder_dataloader = DataLoader(train_encoder_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_encoder_dataloader = DataLoader(valid_encoder_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_encoder_dataloader = DataLoader(test_encoder_data, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064797,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "QUFPEkCGuZuI",
    "outputId": "320cd75b-2b78-45e9-eb07-bff2870114b3"
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_encoder_dataloader))\n",
    "display_image(train_features[0].unsqueeze(0), title='Example map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1641398064798,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "8v4ztNn-x2Mf",
    "outputId": "fe0c867e-11c1-46bd-a566-cab6fcfb650c"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {0} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create encoder model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, input_size):\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.dense1 = nn.Sequential(nn.Linear(input_size, 1512), nn.PReLU())\n",
    "\t\tself.dense2 = nn.Sequential(nn.Linear(1512, 556), nn.PReLU())\n",
    "\t\tself.dense3 = nn.Sequential(nn.Linear(556, 128), nn.PReLU())\n",
    "\t\tself.dense4 = nn.Linear(128, 32)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = self.dense4(x)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, output_size):\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\t\tself.dense1 = nn.Sequential(nn.Linear(32, 128), nn.PReLU())\n",
    "\t\tself.dense2 = nn.Sequential(nn.Linear(128, 556), nn.PReLU())\n",
    "\t\tself.dense3 = nn.Sequential(nn.Linear(556, 1512), nn.PReLU())\n",
    "\t\tself.dense4 = nn.Sequential(nn.Linear(1512, output_size))\n",
    "\t\tself.unflatten = nn.Unflatten(1, (120, 120))\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = self.dense4(x)\n",
    "\t\tx = self.unflatten(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ResUNet, self).__init__()\n",
    "        self.Encoder = Encoder(input_size)\n",
    "        self.Decoder = Decoder(input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x\n",
    "\n",
    "Enet = ResUNet(14400).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractive_mse_loss(model, output, target):\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    key = str(list(model.state_dict().keys())[-2])\n",
    "    last_weigths = model.state_dict()[key]\n",
    "\n",
    "    mse = mse_loss(output, target)\n",
    "    lam = 1e-3\n",
    "    contractive_loss = torch.sum(Variable(last_weigths)**2, dim=1).sum().mul_(lam)\n",
    "\n",
    "    return mse + contractive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1641398064800,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "3jCsfnuo2_VY"
   },
   "outputs": [],
   "source": [
    "def train_encoder(model, optimizer, loss_fn, train_dataloader, valid_dataloader):\n",
    "\n",
    "    for i in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        it = 1\n",
    "        model.train()\n",
    "        with tqdm(train_dataloader, unit=\"batch\", leave=False) as pbar:\n",
    "            for X, y in pbar:\n",
    "                pbar.set_description(f\"Epoch {i + 1}/{epochs} training\")\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(model, pred, y)\n",
    "                total_train_loss += loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_postfix(loss=total_train_loss / it)\n",
    "                it += 1\n",
    "\n",
    "        it = 1\n",
    "        with tqdm(valid_dataloader, unit=\"batch\") as pbar:\n",
    "            with torch.no_grad():\n",
    "                for X, y in pbar:\n",
    "                    pbar.set_description(f\"Epoch {i + 1}/{epochs} validating\")\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "\n",
    "                    pred = model(X)\n",
    "                    loss = loss_fn(model, pred, y)\n",
    "                    total_valid_loss += loss\n",
    "                    pbar.set_postfix(loss = total_train_loss.item() / len(train_dataloader), valid_loss = total_valid_loss.item() / it)\n",
    "                    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1641398065281,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "NGCOrIAd5EiH"
   },
   "outputs": [],
   "source": [
    "def test_encoder(model, loss_fn, dataloader):\n",
    "    test_loss = 0\n",
    "    with tqdm(dataloader, unit=\"batch\") as pbar:\n",
    "        with torch.no_grad():\n",
    "            it = 1\n",
    "            for X, y in pbar:\n",
    "                pbar.set_description(f\"Testing\")\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(model, pred, y).item()\n",
    "                pbar.set_postfix(test_loss=test_loss / it)\n",
    "                it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9190,
     "status": "ok",
     "timestamp": 1641398074469,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "bYtDJkXN36hr",
    "outputId": "ccda881d-d536-446c-c2c2-10e059ba8673"
   },
   "outputs": [],
   "source": [
    "loss_fn = contractive_mse_loss\n",
    "optimizer = torch.optim.Adagrad(Enet.parameters(), lr=1e-3)\n",
    "\n",
    "if not os.path.exists(enet_filename) or train_enet:\n",
    "    epochs = 60\n",
    "    train_encoder(Enet, optimizer, loss_fn, train_encoder_dataloader, valid_encoder_dataloader)\n",
    "    test_encoder(Enet, loss_fn, test_encoder_dataloader)\n",
    "    torch.save(Enet.state_dict(), enet_filename)\n",
    "else:\n",
    "    Enet.load_state_dict(torch.load(enet_filename))\n",
    "    Enet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1641398303376,
     "user": {
      "displayName": "AlterArm",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiWK-wxB4-D5jlbs06y0_VdCNGrHcXmI4AQYyiejQ=s64",
      "userId": "02741529306535878932"
     },
     "user_tz": -60
    },
    "id": "QCQgyA_15PvK",
    "outputId": "cad80819-974e-40b4-c66a-def1b9ffc767"
   },
   "outputs": [],
   "source": [
    "# Display Results\n",
    "test_image, _ = next(iter(test_encoder_dataloader))\n",
    "display_image(test_image[0].unsqueeze(0), 'Example map')\n",
    "\n",
    "result = Enet(test_image.to(device))\n",
    "display_image(result[0].cpu().unsqueeze(0), 'Map after reconstruction')\n",
    "\n",
    "encoded = Enet.Encoder(test_image.to(device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create path planning dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_dir, paths_dir, encoder):\n",
    "        self.images_dir = images_dir\n",
    "        self.paths_dir = paths_dir\n",
    "        self.encoder = encoder\n",
    "\n",
    "        images_paths = Path(paths_dir).glob('*/')\n",
    "        self.sample_names = [x.name[0:-5] for x in images_paths if str(x).endswith('.json')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_names)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.images_dir + self.sample_names[idx][:-7] + '.png'\n",
    "        path_name = self.paths_dir + self.sample_names[idx] + '.json'\n",
    "\n",
    "        image = plt.imread(image_name)\n",
    "\n",
    "        image = Tensor(image).to(device)\n",
    "        image = image.permute(2,1,0)\n",
    "        image = image[2, :, :]\n",
    "\n",
    "        encoded_img = self.encoder(image.unsqueeze(0))[0].detach().cpu()\n",
    "\n",
    "        file = open(path_name)\n",
    "        data = Tensor(json.load(file))\n",
    "\n",
    "        if len(data) == 2:\n",
    "            pos_start = data[0] / image.shape[-1]\n",
    "            pos_goal = data[1] / image.shape[-1]\n",
    "            pos_pred = torch.round((data[0] + data[1]) / 2) / image.shape[-1]\n",
    "        \n",
    "        else:\n",
    "            # Choose random consecutive points from planned path\n",
    "            rand = np.random.randint(1, len(data) - 1)\n",
    "            pos_start = data[rand - 1] / image.shape[-1]\n",
    "            pos_goal = data[rand] / image.shape[-1]\n",
    "            pos_pred = data[rand + 1] / image.shape[-1]\n",
    "\n",
    "        input_data = torch.cat([torch.flatten(encoded_img), pos_start, pos_goal])\n",
    "        input_data.requires_grad = True\n",
    "\n",
    "        return input_data, pos_pred\n",
    "\n",
    "    def get_image_path(self, idx):\n",
    "\n",
    "        image_path = self.images_dir + self.sample_names[idx][:-7] + '.png'\n",
    "\n",
    "        return image_path\n",
    "\n",
    "\n",
    "train_dataset = PathDataset(train_images_dir, train_paths_dir, Enet.Encoder)\n",
    "valid_dataset_known = PathDataset(valid_known_images_dir, valid_known_paths_dir, Enet.Encoder)\n",
    "valid_dataset_unknown = PathDataset(valid_unknown_images_dir, valid_unknown_paths_dir, Enet.Encoder)\n",
    "test_dataset_known = PathDataset(test_known_images_dir, test_known_paths_dir, Enet.Encoder)\n",
    "test_dataset_unknown = PathDataset(test_unknown_images_dir, test_unknown_paths_dir, Enet.Encoder)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True, pin_memory=True)\n",
    "valid_dataloader_known = DataLoader(valid_dataset_known, batch_size=100, shuffle=True, pin_memory=True)\n",
    "valid_dataloader_unknown = DataLoader(valid_dataset_unknown, batch_size=100, shuffle=True, pin_memory=True)\n",
    "test_dataloader_known = DataLoader(test_dataset_known, batch_size=100, shuffle=True, pin_memory=True)\n",
    "test_dataloader_unknown = DataLoader(test_dataset_unknown, batch_size=100, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanningNetwork(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(PlanningNetwork, self).__init__()\n",
    "\n",
    "        enc_img_size = 36\n",
    "        self.dense1 = nn.Sequential(nn.Linear(enc_img_size, 1280), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense2 = nn.Sequential(nn.Linear(1280, 1024), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense3 = nn.Sequential(nn.Linear(1024, 896), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense4 = nn.Sequential(nn.Linear(896, 768), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense5 = nn.Sequential(nn.Linear(768, 512), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense6 = nn.Sequential(nn.Linear(512, 384), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense7 = nn.Sequential(nn.Linear(384, 256), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense8 = nn.Sequential(nn.Linear(256, 128), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense9 = nn.Sequential(nn.Linear(128, 64), nn.PReLU(), nn.Dropout(p))\n",
    "        self.dense10 = nn.Sequential(nn.Linear(64, 32), nn.PReLU())\n",
    "        self.dense11 = nn.Sequential(nn.Linear(32, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        x = self.dense7(x)\n",
    "        x = self.dense8(x)\n",
    "        x = self.dense9(x)\n",
    "        x = self.dense10(x)\n",
    "        x = self.dense11(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "Pnet = PlanningNetwork().to(device)\n",
    "print('Model parameters:', sum(p.numel() for p in Pnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pnet_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "\n",
    "        loss = Tensor([0]).to(device)\n",
    "        for i in range(len(target)):\n",
    "            loss += torch.square(output[i, 0] - target[i, 0])\n",
    "            loss += torch.square(output[i, 1] - target[i, 1])\n",
    "        \n",
    "        loss /= (target.shape[0] * 2)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mpnet(model, optimizer, loss_fn, train_dataloader, valid_dataloader):\n",
    "\n",
    "    for i in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        it = 1\n",
    "        model.train()\n",
    "        with tqdm(train_dataloader, unit=\"batch\", leave=False) as pbar:\n",
    "            for X, y in pbar:\n",
    "                pbar.set_description(f\"Epoch {i + 1}/{epochs} training\")\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "                total_train_loss += loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_postfix(loss=total_train_loss / it)\n",
    "                it += 1\n",
    "\n",
    "        it = 1\n",
    "        with tqdm(valid_dataloader, unit=\"batch\") as pbar:\n",
    "            with torch.no_grad():\n",
    "                for X, y in pbar:\n",
    "                    pbar.set_description(f\"Epoch {i + 1}/{epochs} validating\")\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "\n",
    "                    pred = model(X)\n",
    "                    loss = loss_fn(pred, y)\n",
    "                    total_valid_loss += loss\n",
    "                    pbar.set_postfix(loss = total_train_loss.item() / len(train_dataloader), valid_loss = total_valid_loss.item() / it)\n",
    "                    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mpnet(model, loss_fn, test_dataloader):\n",
    "    test_loss = 0\n",
    "    with tqdm(test_dataloader, unit=\"batch\") as pbar:\n",
    "        with torch.no_grad():\n",
    "            it = 1\n",
    "            for X, y in pbar:\n",
    "                pbar.set_description(f\"Testing\")\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                pbar.set_postfix(test_loss=test_loss / it)\n",
    "                it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = Pnet_loss().forward\n",
    "optimizer = torch.optim.Adagrad(Pnet.parameters(), lr=1e-4)\n",
    "\n",
    "if not os.path.exists(pnet_filename) or train_pnet:\n",
    "    epochs = 5\n",
    "    train_mpnet(Pnet, optimizer, loss_fn, train_dataloader, valid_dataloader_known)\n",
    "    test_mpnet(Pnet, loss_fn, test_dataloader_known)\n",
    "    torch.save(Pnet.state_dict(), pnet_filename)\n",
    "else:\n",
    "    Pnet.load_state_dict(torch.load(pnet_filename))\n",
    "    Pnet.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "def display_results(model, dataset, idx):\n",
    "\n",
    "    X, pos_pred = dataset.__getitem__(idx)\n",
    "\n",
    "    print(X.to(device).unsqueeze(0))\n",
    "\n",
    "    result = model(X.to(device).unsqueeze(0))\n",
    "\n",
    "    pos_start = X[-4:-2]\n",
    "    pos_goal = X[-2:]\n",
    "\n",
    "    image_path = dataset.get_image_path(idx)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    points = [pos_start, result[0].detach().cpu(), pos_goal]\n",
    "    colors = [(0, 255, 0), (255, 255, 0), (255, 0, 0)]\n",
    "\n",
    "    for point, color in zip(points, colors):\n",
    "        point = torch.round(point * 120)\n",
    "        point = point.type(torch.uint8)\n",
    "        \n",
    "        image = cv2.rectangle(image, (point - 2).detach().numpy(), (point + 2).detach().numpy(), color, -1)\n",
    "\n",
    "    for i in range(len(points) - 1):\n",
    "        point1 = torch.round(points[i] * 120)\n",
    "        point1 = point1.type(torch.uint8)\n",
    "\n",
    "        point2 = torch.round(points[i + 1] * 120)\n",
    "        point2 = point2.type(torch.uint8)\n",
    "\n",
    "        image = cv2.line(image, point1.detach().numpy(), point2.detach().numpy(), (0, 255, 0), 1)\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "display_results(Pnet, test_dataset_known, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Replaning(a, b):\n",
    "#     pass\n",
    "\n",
    "# N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Algorithm 1\n",
    "# def MPNet(x_init, x_goal, x_obs):\n",
    "#     Z = Enet.Encoder(x_obs)\n",
    "#     Tau = NeuralPlanner(x_init, x_goal, Z)\n",
    "#     if Tau:\n",
    "#         Tau = lazy_states_contraction(Tau)\n",
    "\n",
    "#         if is_feasible(Tau):\n",
    "#             return Tau\n",
    "#         else:\n",
    "#             Tau_new = Replaning(Tau, Z)\n",
    "#             Tau_new = lazy_states_contraction(Tau_new)\n",
    "#             if is_feasible(Tau_new):\n",
    "#                 return Tau_new\n",
    "#     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Algorithm 2\n",
    "# def NeuralPlanner(x_start, x_goal, Z):\n",
    "#     Tau_a = [x_start]\n",
    "#     Tau_b = [x_goal]\n",
    "#     Tau = 0\n",
    "\n",
    "#     for i in range(N):\n",
    "#         x_new = Pnet(Z, Tau_a[-1], Tau_b[-1])\n",
    "#         Tau_a.append(x_new)\n",
    "#         connectable = steer_to(Tau_a[-1], Tau_b[-1])\n",
    "\n",
    "#         if connectable:\n",
    "#             Tau = np.concatenate((Tau_a, Tau_b))\n",
    "#             return Tau\n",
    "\n",
    "#         Tau_a, Tau_b = Tau_b, Tau_a\n",
    "\n",
    "#     return 0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPwQqSrx/eWM5U7H1MeaJ9I",
   "collapsed_sections": [],
   "name": "motion_planning_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
